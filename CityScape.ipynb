{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j7gmQ-LfGqJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing some files\n",
        "from re import X\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "8P2Jcr-W1ZGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci1GN85AUce7",
        "outputId": "50ac0998-7538-43ee-8f60-9de4728854c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/archive/cityscapes_data/train'\n",
        "val_path = '/content/drive/MyDrive/archive/cityscapes_data/val'\n",
        "print(len(train_path))\n",
        "print(len(val_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9kgXkbxdNve",
        "outputId": "f1dbecfb-137d-41f8-b27f-3ed736f1094f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing dataset\n",
        "fig,ax = plt.subplots(5,2,figsize=(10,30))\n",
        "if len(train_path) >= 5:\n",
        "    fig, ax = plt.subplots(5, 2, figsize=(10, 30))\n",
        "    for i in range(5):\n",
        "        img = plt.imread(train_path[i])\n",
        "        ax[i][0].imshow(img[:, :256])\n",
        "        ax[i][1].imshow(img[:, 256:])\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough elements in train_path. Ensure it has at least 5 file paths.\")"
      ],
      "metadata": {
        "id": "HQkhwuQxzTMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Custom Dataset"
      ],
      "metadata": {
        "id": "okrHhunUIEDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = []\n",
        "valid_dataset = []"
      ],
      "metadata": {
        "id": "93MU7uDBoI4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, image_path, transform_img = None, transform_label = None):\n",
        "        self.image_path = image_path\n",
        "        self.transform_img = transform_img\n",
        "        self.transform_label = transform_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = plt.imread(self.image_path[idx])\n",
        "\n",
        "        image, label = img[:,:img.shape[1]//2], img[:,img.shape[1]//2:]\n",
        "\n",
        "        if self.transform_img:\n",
        "            image = self.transform_img(image)\n",
        "\n",
        "        if self.transform_label:\n",
        "            label = self.transform_label(label)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "htqxhEaFk3H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Transforms / Data Augmentation\n",
        "myTransformImage = transforms.Compose([\n",
        "    transforms.Resize((572,572)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "myTransformLabel = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = dataset(train_path, myTransformImage, myTransformLabel)\n",
        "valid_dataset = dataset(val_path, myTransformImage, myTransformLabel)"
      ],
      "metadata": {
        "id": "tFvLxe0WHl4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size= 4, shuffle = True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size= 1, shuffle = True)"
      ],
      "metadata": {
        "id": "MJKyDrrdJiFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Batch"
      ],
      "metadata": {
        "id": "BvI9eAjeId5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(whole_batch):\n",
        "    images, label = whole_batch[0], whole_batch[1]\n",
        "    images = images.numpy()\n",
        "    label = label.numpy()\n",
        "    fig, lab = plt.subplots(5, 2, figsize = (10, 30))\n",
        "\n",
        "    for i in range(5):\n",
        "        lab[i][0].imshow(np.transpose(images[i], (1,2,0)))\n",
        "        lab[i][1].imshow(np.transpose(label[i], (1,2,0)))"
      ],
      "metadata": {
        "id": "Ii6qcv8DqO2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "show_batch(next(data_iter))"
      ],
      "metadata": {
        "id": "DrO9U-EotPst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize images, pass the list\n",
        "def show(pckt):\n",
        "\n",
        "    iters = 1\n",
        "    if len(pckt[0].shape) > 3:\n",
        "        iters = pckt[0].shape[0]\n",
        "        for j in range(iters):\n",
        "            img = [None]*3\n",
        "            n = 3\n",
        "            labels = ['Actual', 'Label', 'Predicted']\n",
        "            fig, ax = plt.subplots(1, n, figsize=(10, 30))\n",
        "            for i in range(n):\n",
        "\n",
        "                x = torch.Tensor.cpu(pckt[j][i])\n",
        "                x = x.detach().numpy()\n",
        "                ax[i].imshow(np.transpose(x,(1,2,0)))\n",
        "                ax[i].set_title(labels[i])\n",
        "    else:\n",
        "        img = [None]*3\n",
        "        n = len(pckt)\n",
        "        labels = ['Actual', 'Label', 'Predicted']\n",
        "        fig, ax = plt.subplots(1, n, figsize=(10, 30))\n",
        "        for i in range(n):\n",
        "            x = torch.Tensor.cpu(pckt[i])\n",
        "            x = x.detach().numpy()\n",
        "            ax[i].imshow(np.transpose(x,(1,2,0)))\n",
        "            ax[i].set_title(labels[i])"
      ],
      "metadata": {
        "id": "yDozVQzhul3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "img, lab = next(data_iter)\n",
        "\n",
        "show([img[0], lab[0]])\n",
        "print(img[0].shape)"
      ],
      "metadata": {
        "id": "uaUmmaQEuo9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "sueT3gTCurnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyfNlG-1Rznr"
      },
      "outputs": [],
      "source": [
        "# Unet Architecture\n",
        "#kernel_tensor = tf.random.normal([3,3,1,64])\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv_layer_1 = nn.Conv2d(3,64,3,1)\n",
        "        self.conv_layer_2 = nn.Conv2d(64,64,3,1)\n",
        "\n",
        "        self.conv_layer_3 = nn.Conv2d(64,128,3,1)\n",
        "        self.conv_layer_4 = nn.Conv2d(128,128,3,1)\n",
        "\n",
        "        self.conv_layer_5 = nn.Conv2d(128,256,3,1)\n",
        "        self.conv_layer_6 = nn.Conv2d(256,256,3,1)\n",
        "\n",
        "        self.conv_layer_7 = nn.Conv2d(256,512,3,1)\n",
        "        self.conv_layer_8 = nn.Conv2d(512,512,3,1)\n",
        "\n",
        "        self.conv_layer_9 = nn.Conv2d(512,1024,3,1)\n",
        "        self.conv_layer_10 = nn.Conv2d(1024,1024,3,1)\n",
        "\n",
        "        self.upconv_layer_1 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "\n",
        "        self.De_conv_layer_1 = nn.Conv2d(1024,512,3,1)\n",
        "        self.De_conv_layer_2 = nn.Conv2d(512,512,3,1)\n",
        "\n",
        "        self.upconv_layer_2 = nn.ConvTranspose2d(512,256,2,2)\n",
        "\n",
        "        self.De_conv_layer_3 = nn.Conv2d(512,256,3,1)\n",
        "        self.De_conv_layer_4 = nn.Conv2d(256,256,3,1)\n",
        "\n",
        "        self.upconv_layer_3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "\n",
        "        self.De_conv_layer_5 = nn.Conv2d(256,128,3,1)\n",
        "        self.De_conv_layer_6 = nn.Conv2d(128,128,3,1)\n",
        "\n",
        "        self.upconv_layer_4 = nn.ConvTranspose2d(128,64,2,2)\n",
        "\n",
        "        self.De_conv_layer_7 = nn.Conv2d(128,64,3,1)\n",
        "        self.De_conv_layer_8 = nn.Conv2d(64,64,3,1)\n",
        "\n",
        "        self.final_conv_layer = nn.Conv2d(64,2,1,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):                               # 1x572x572\n",
        "        c1_out = F.relu(self.conv_layer_1(x))           # 64x570x570\n",
        "        c2_out = F.relu(self.conv_layer_2(c1_out))      # 64x568x568\n",
        "        print(c1_out.shape, c2_out.shape)\n",
        "\n",
        "        m1 =  nn.MaxPool2d(2, stride=2)\n",
        "        p1_out = m1(c2_out)                             # 64x284x284\n",
        "        print(p1_out.shape)\n",
        "\n",
        "        c3_out = F.relu(self.conv_layer_3(p1_out))      # 128x282x282\n",
        "        c4_out = F.relu(self.conv_layer_4(c3_out))      # 128x280x280\n",
        "        print(c3_out.shape,c4_out.shape)\n",
        "\n",
        "        m2 =  nn.MaxPool2d(2, stride=2)\n",
        "        p2_out = m1(c4_out)                             # 128x140x140\n",
        "        print(p2_out.shape)\n",
        "\n",
        "        c5_out = F.relu(self.conv_layer_5(p2_out))      # 256x138x138\n",
        "        c6_out = F.relu(self.conv_layer_6(c5_out))      # 256x136x136\n",
        "        print(c5_out.shape,c6_out.shape)\n",
        "\n",
        "        m3 =  nn.MaxPool2d(2, stride=2)\n",
        "        p3_out = m1(c6_out)                             # 256x68x68\n",
        "        print(p3_out.shape)\n",
        "\n",
        "        c7_out = F.relu(self.conv_layer_7(p3_out))      # 512x66x66\n",
        "        c8_out = F.relu(self.conv_layer_8(c7_out))      # 512x64x64\n",
        "        print(c7_out.shape,c8_out.shape)\n",
        "\n",
        "        m4 =  nn.MaxPool2d(2, stride=2)\n",
        "        p4_out = m1(c8_out)                             # 512x32x32\n",
        "        print(p4_out.shape)\n",
        "\n",
        "        c9_out = F.relu(self.conv_layer_9(p4_out))      # 1024x30x30\n",
        "        c10_out = F.relu(self.conv_layer_10(c9_out))    # 1024x28x28\n",
        "        print(c9_out.shape,c10_out.shape)\n",
        "\n",
        "        uc1_out = self.upconv_layer_1(c10_out)          # Upconv from 1024x28x28 to 512x56x56  - SWARNENDU\n",
        "        print(\"size of the layer:\", uc1_out.shape)\n",
        "\n",
        "        cropped_tensor_1 = c8_out[:, :, 4:60, 4:60]     # Cropping from 512x64x64 to 512x56x56  - SWARNENDU\n",
        "        combined_tensor_1 = torch.cat((cropped_tensor_1,uc1_out), dim=1)  # Concat across Channel Dimension, dim=1\n",
        "        print(\"Combined tensor shape:\", combined_tensor_1.shape)       # 1024x56x56\n",
        "\n",
        "        dc_out_1 = F.relu(self.De_conv_layer_1(combined_tensor_1))\n",
        "        dc_out_2 = F.relu(self.De_conv_layer_2(dc_out_1))\n",
        "        print(dc_out_2.shape)\n",
        "\n",
        "        uc2_out = self.upconv_layer_2(dc_out_2)\n",
        "        print(\"size of the layer:\", uc2_out.shape)\n",
        "\n",
        "        cropped_tensor_2 = c6_out[:, :, 16:120, 16:120]\n",
        "        combined_tensor_2 = torch.cat((cropped_tensor_2,uc2_out), dim=1)        # 512x104x104\n",
        "\n",
        "        dc_out_3 = F.relu(self.De_conv_layer_3(combined_tensor_2))              # 256x102x102\n",
        "        dc_out_4 = F.relu(self.De_conv_layer_4(dc_out_3))                       # 256x100x100\n",
        "        print(dc_out_3.shape)      # 256x100x100\n",
        "\n",
        "        uc3_out = self.upconv_layer_3(dc_out_4)\n",
        "        print(\"size of the layer:\", uc3_out.shape)    #128x200x200\n",
        "\n",
        "        cropped_tensor_3 = c4_out[:, :, 40:240, 40:240]     #128x200x200\n",
        "        combined_tensor_3 = torch.cat((cropped_tensor_3,uc3_out), dim=1)      # 26x200x200\n",
        "\n",
        "        dc_out_5 = F.relu(self.De_conv_layer_5(combined_tensor_3))\n",
        "        dc_out_6 = F.relu(self.De_conv_layer_6(dc_out_5))\n",
        "        print(dc_out_3.shape)\n",
        "\n",
        "        uc4_out = self.upconv_layer_4(dc_out_6)\n",
        "        print(\"size of the layer:\", uc4_out.shape)\n",
        "\n",
        "        cropped_tensor_4 = c2_out[:, :, 88:480, 88:480]\n",
        "        combined_tensor_4 = torch.cat((cropped_tensor_4,uc4_out), dim=1)\n",
        "\n",
        "        dc_out_7 = F.relu(self.De_conv_layer_7(combined_tensor_4))              # 64x390x390\n",
        "        dc_out_8 = F.relu(self.De_conv_layer_8(dc_out_7))                       # 64x388x388\n",
        "        print(dc_out_8.shape)      # 64x388x388\n",
        "\n",
        "        final_layer_out = F.softmax(self.final_conv_layer(dc_out_8),dim =1)    # 2x388x388\n",
        "\n",
        "        return (final_layer_out)\n",
        "\n",
        "model = UNet()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "model = Unet().float().to(device)\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "JQcAJK_pUa4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "vOB6IUblu9cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "qwmfvCwcJIAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    trainloss = 0\n",
        "    valloss = 0\n",
        "    c = 0\n",
        "    for img, lab in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        img = img.to(device)\n",
        "        lab = lab.to(device)\n",
        "        output = model(img)\n",
        "        loss = loss_func(output, lab)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trainloss += loss.item()\n",
        "\n",
        "\n",
        "        if epoch % 5 == 0 and c < 2:\n",
        "            show([img[0], lab[0], output[0]])\n",
        "            c += 1\n",
        "    train_loss.append(trainloss/len(train_loader))\n",
        "\n",
        "\n",
        "\n",
        "    for img, lab in tqdm(valid_loader):\n",
        "        img = img.to(device)\n",
        "        lab = lab.to(device)\n",
        "        output = model(img)\n",
        "        loss = loss_func(output, lab)\n",
        "        valloss += loss.item()\n",
        "    val_loss.append(valloss/len(valid_loader))\n",
        "\n",
        "    print(\"epoch : {} ,train loss : {} ,valid loss : {} \".format(i,train_loss[-1],val_loss[-1]))"
      ],
      "metadata": {
        "id": "ofq7rTw3u-H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss,color='b',label='train loss')\n",
        "plt.plot(val_loss,color='r',label = 'val_loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "mfSwgfphvCr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for img, lab in valid_loader:\n",
        "    img = img.to(device)\n",
        "    label = lab.to(device)\n",
        "    output = model(img)\n",
        "    show([img[0],label[0],output[0]])\n",
        "    if c>20:\n",
        "        break\n",
        "    c+=1"
      ],
      "metadata": {
        "id": "qooKxLGyvG-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}